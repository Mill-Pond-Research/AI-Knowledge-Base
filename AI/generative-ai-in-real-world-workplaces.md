# Generative AI in Real-World Workplaces: The Second Microsoft Report on AI and Productivity Research

## Table of Contents

1. Introduction
2. Related Work
3. Studies and Results
   3.1 Studies of Workers Using AI on the Job
   3.2 A Selection of New Lab Studies
4. Discussion
5. Conclusion
6. References

## Document Overview

This knowledge base entry is based on the second Microsoft report on AI and Productivity Research, titled "Generative AI in Real-World Workplaces". The document synthesizes findings from over a dozen recent studies conducted by Microsoft researchers, focusing on the impact of generative AI tools like Microsoft Copilot in actual workplace environments. It provides valuable insights into how AI is affecting productivity, workflow changes, and the challenges and opportunities presented by this technology in various professional contexts.

The significance of this report lies in its focus on real-world applications of AI, moving beyond the lab-based studies that have dominated previous research. It offers a more nuanced understanding of how generative AI is being integrated into daily work practices across different roles and functions.

## 1. Introduction

The introduction sets the context for the report, highlighting the shift from lab-based studies to real-world observations of generative AI's impact on productivity. 

Key points:

- Previous research, including Microsoft's first AI and Productivity Report, largely focused on lab-based studies.
- This report concentrates on how people apply Copilot and other generative AI tools in their regular work.
- The research includes what is believed to be the largest randomized controlled trial on the introduction of generative AI in real workplaces.

The introduction outlines several high-level observations:

1. "Generative AI is already helping people be measurably more productive in their day-to-day jobs."
2. "As expected, the productivity story in real-world workflows is more complex than observed in lab studies."
3. "Productivity gains associated with generative AI, including time and accuracy, vary by role, function and organization."
4. "Variance in adoption and utilization influences AI's impact."
5. "Early studies suggest generative AI may affect the cognitive effort required for task completion."

The authors note that while the report synthesizes learnings from various studies, many of these studies have not yet undergone peer review. They also acknowledge that the work was funded by Microsoft, which has a commercial interest in demonstrating Copilot's effectiveness.

## 2. Related Work

This section highlights notable studies from researchers outside of Microsoft that examine generative AI's impact on productivity in real-world contexts. These studies consistently show that the gains predicted by lab studies translate into significant impact when AI is used for real work.

Key studies and findings:

1. Brynjolfsson et al. (2023):
   - Studied an AI-based conversational assistant for customer service agents in a call center.
   - Found that agents with the assistant resolved 14% more issues per hour than those without.
   - Largest impact was on novice and low-skilled workers, with little effect on experienced or highly-skilled workers.

2. Otis et al. (2024):
   - Examined the effects of a generative AI-powered entrepreneurship support tool on Kenyan entrepreneurs' business performance.
   - Entrepreneurs with above-median performance saw gains of 0.19 standard deviations in performance when using the AI tool.
   - Entrepreneurs with below-median performance saw a decrease of 0.09 standard deviations.
   - Emphasizes the importance of contextual factors in productivity gains from generative AI.

3. Wiles and Horton (2024):
   - Explored how having an LLM generate a first draft of a job posting affected postings and hiring on a large online labor market.
   - Found that the AI tool decreased time spent writing posts and increased the number of posts completed.
   - No effect on the number of hires was observed.
   - Suggests that AI may lead to the posting of less important jobs and less effort in writing job posts.

4. Yeverechyahu et al. (2024):
   - Studied generative AI effects on coding activity in open-source repositories.
   - Found a significant jump in contributions due to GitHub Copilot.
   - Increase was larger for "maintenance solutions" than for "new code development".

5. Rio-Chanona et al. (2023):
   - Provided evidence that the availability of generative AI programming tools substantially reduced participation in online programming forums.
   - Suggests a potential "paradox of reuse" dynamics in the generative AI ecosystem.

The authors note that these studies begin to reveal nuances in how AI is used, highlighting the importance of contextual factors such as skill or task selection on AI's impact. They also provide early evidence that the presence of AI may impact people's behavior and the larger ecosystem.

## 3. Studies and Results

This section presents an overview of studies recently conducted by researchers at Microsoft, focusing on those that speak to real-world implications of generative AI.

### 3.1 Studies of Workers Using AI on the Job

#### Early Access Program Telemetry Study

Researchers: Eleanor Dillon, Sonia Jaffe, Sida Peng, and Alexia Cambon

This large-scale randomized controlled field experiment of Copilot for Microsoft 365 involved over 60 organizations and over 6000 individual employees across various industries and occupations.

Key findings:

1. Email behavior:
   - "Those with Copilot for Microsoft 365 read 11% fewer individual emails and spent 4% less time interacting with them, compared to people without Copilot."
   - "Some organizations saw larger effects with relative decreases of up to 20 or 25% in both emails read and time spent interacting with email."

2. Meeting attendance:
   - Effects varied across organizations.
   - "Of the 47 organizations that have been in the study the longest, 10 saw a statistically significant decrease in attended meetings, with an average decrease of .39 meetings per day on a pre-Copilot average of 3 meetings."
   - "14 customers saw a statistically significant increase in meetings with an average increase of .36 meetings per day on a pre-Copilot average of 2 meetings."

3. Document creation and editing:
   - "People with Copilot also created and edited more documents than those without Copilot."
   - "Overall people edited 10% more documents, with heavy users of Word, Excel, and PowerPoint seeing an increase of 13% (on a higher baseline)."
   - "Some organizations saw increases in the 25-30% range."

The researchers note that the study is ongoing and they plan to explore additional outcomes and spillover effects.

#### Work Trend Index Survey

This survey was conducted with 31,000 full-time employed or self-employed knowledge workers across 31 countries.

Key findings:

1. Unsanctioned AI tool use:
   - "Of respondents who used AI, 78% used at least some AI tools not provided by their organization."

2. AI Power Users:
   - Defined as individuals "familiar with generative AI, using it at work at least several times a week, and saving more than 30 minutes a day by using it."
   - 29% of respondents who used AI fell into this category.
   - Power users had noticeably lower use of unsanctioned AI (66% vs. the non-power user average of 83%, p<.05).

3. Predictors of AI power usage:
   - Regular experimentation with AI emerged as the most significant predictor of AI power usage classification.

#### Copilot Usage in the Workplace Survey

Researchers: Alexia Cambon, Alex Farach, Margarita Bermejo-Cano, and Eric Knudsen

This ongoing survey focuses specifically on Copilot for Microsoft 365, asking enterprise Copilot users about perceived benefits, time savings, and overall job satisfaction.

Key findings:

1. Benefits increase with usage duration:
   - "Respondents who had been using Copilot for more than 10 weeks reported greater benefits compared to those with shorter usage durations."
   - Example: For the question "Using Copilot in Teams allows me to attend fewer meetings," those using Copilot for 3-6 weeks had an average response of 2.66, while those with more than 10 weeks of usage had an average of 3.06.

2. Improved job satisfaction:
   - For the question "Using Copilot helps me to enjoy my work more," the average for the 3-6 week group was 3.4, and for the over 10-weeks group, it was 3.6.

#### Study on Generative Search Engines and Task Complexity

Researchers: Siddharth Suri, Scott Counts, Leijie Wang, Chacha Chen, Mengting Wan, Tara Safavi, Jennifer Neville, Chirag Shah, Ryen W. White, Reid Andersen, Georg Buscher, Sathish Manivannan, Nagu Rangan, and Longqi Yang

This study analyzed 80,000 randomly selected, de-identified conversations from the consumer version of Copilot in Bing and traditional Bing searches.

Key findings:

1. Focus on knowledge work:
   - "Chats with Bing Copilot tend to focus on topics related to knowledge work, such as 'Translation and language learning,' 'Creative writing and editing,' and 'Programming and scripting.'"
   - "72.9% of the Copilot conversations are in knowledge work domains compared to 37% of Bing Search sessions."

2. Task complexity:
   - "Over three-quarters of traditional search sessions, but less than half of Copilot conversations were for 'Remember' tasks."
   - "13.4% of traditional search sessions and 37% of Copilot sessions were high-complexity."

The researchers interpret these findings as evidence that "generative AI helping people with tasks that used to be done with much more human effort; LLMs shift the frontier of which tasks machines can help with â€“ and how helpful they are."

### 3.2 A Selection of New Lab Studies

#### Comparing the Effect of Different Task Types on Effective Use of GitHub Copilot

Researchers: Steven Clarke and Ben Hanrahan

This study investigated the conditions under which a developer might expect to benefit most from GitHub Copilot.

Key findings:

- "With the familiar task Copilot use resulted in 36% time-savings (p<.05) and 48% fewer issues (p=.12)."
- "In contrast, no substantial difference was observed between Copilot and non-Copilot groups for the less familiar task."

#### Understanding the Impact Copilot for Security Has for Security Professionals

Researchers: Ben Edelman, James Bono, Sida Peng, Roberto Rodriguez, and Sandra Ho

This study extended previous lab experiments to focus on security professionals who use security tools in their day-to-day jobs.

Key findings:

- "Those with Copilot were 7% more accurate on the multiple-choice questions (p<.05)."
- "Study participants with Copilot included 49% more of those key facts in their incident summary reports (p<.05)."
- "Subjects with Copilot were 23% faster overall (p<.05)."

#### Experiment with Licensing Chatbot for Sellers

Researchers: Donald Ngwe, Ried Peckham, Ulrike Gruber-Gremlich, and Tyler Smith

This lab study examined how a "licensing chatbot" facilitated sellers' ability to answer customer questions.

Key findings:

- "Sellers with the chatbot answered multiple choice questions 3.4 minutes (39%, p<.05) faster and accuracy improved by 25 percentage points (p<.05)."
- "In the open-ended questions, speed, accuracy, completeness, and suitability ratings all improved 34-56% (p<.05)."

#### The Effect of Copilot in a Multi-lingual Context

Researchers: Benjamin Edelman and Donald Ngwe

This study explored Copilot in multilingual contexts, examining how it can facilitate collaboration between colleagues with different native languages.

Key findings:

- "For the meeting in English, participants with Copilot answered 16.4% more multiple-choice questions about the meeting correctly, and they were more than twice as likely to get a perfect score."
- "People listening to a meeting in English with Copilot achieved 97.5% accuracy, slightly more accurate than people listening to a meeting in their native Japanese using standard tools (94.8%)."

#### Impact of Generative AI on Metacognition

Researchers: Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel

This review paper explored how generative AI changes the metacognitive demands of a task.

Key points:

- Prompt engineering, prompt iteration, and output evaluation require metacognitive effort that may not be needed when doing a task without assistance.
- The availability of generative AI tools creates a more general burden of deciding how to apply these tools to tasks and workflows.
- The researchers suggest that the metacognitive demands of generative AI can be addressed both by improving users' metacognitive abilities and by reducing the metacognitive demands of the tools.

#### Impact of Copilot on Cognitive Load

Researchers: Madeline Kleiner, Max Meijer, Katie Rotella, and Nora Presson

This study examined the impact of Copilot on cognitive load during a task of creating a sales report.

Key findings:

- "Participants with Copilot reported the task was less mentally demanding on average (30 out of 100) than the control group (55 out of 100)."
- "The improvements for perceived stress and difficulty were similar, with an even larger difference (28 vs. 67 out of 100) for how rushed the task felt."
- No significant difference was found in the Stroop test scores, suggesting that while Copilot made the task feel easier, it may not have affected participants' ability to perform a subsequent task.

## 4. Discussion

The discussion section synthesizes insights from the various studies presented in the report. Key points include:

1. Real-world complexity:
   - "The tasks studied in the lab, for example, have tended to require only general knowledge and skills. In contrast, tasks done in the course of work often require highly-specific knowledge and skills."
   - "Actual information work, however, often includes a huge variety of tasks and much of the unstructured and informal work in people's jobs is not yet directly supported by the first-generation of generative AI tools."

2. Context matters:
   - "When we look at AI's use in the context of real workflows, we see that context matters a lot."
   - "There is an opportunity to further study which individuals and business processes benefit most from AI, and how organizational leaders can enable and encourage AI's productive use."

3. Workflow redesign:
   - "Assuming generative AI follows the path of most general purpose technologies, workflows will, looking forward, be substantially redesigned to better integrate AI."

4. Disconnect between perceived and actual time savings:
   - "One result seen in the above studies and those in our prior work is the common disconnect between the time savings people report from Copilot use and the actual time savings measured."
   - Several potential explanations are offered, including enjoyment of the experience, reduced perception of time due to easier information extraction and processing, and increased perceived time savings due to increased ease of use over time.

5. Focus on individual work:
   - "An important limitation of the above research and much of the literature on AI and productivity is the near total focus on individual work."
   - The authors suggest that future research should focus more on AI's impact on teams and organizations, including cross-functional knowledge and cooperation, social cohesion of teams, and information flow across organizations.

## 5. Conclusion

The conclusion summarizes the key findings and implications of the report:

1. Real-world impact:
   - "The results suggest that the positive productivity effects that have been observed in a lab setting are beginning to manifest in real-world work."

2. Contextual variation:
   - "These gains appear to vary contextually (e.g., by role or usage), and these variations indicate there are ways for individuals, organizations, and tool providers to incorporate generative AI in new ways that produce even larger productivity gains for an even wider array of people."

3. Future potential:
   - The report suggests that there is potential for even greater productivity gains as individuals and organizations learn to better integrate AI into their workflows and as the technology continues to develop.

## 6. References

The report includes an extensive list of references, which are crucial for further exploration of the topic and validation of the findings. Some key references include:

1. Brynjolfsson, E., Li, D., & Raymond, L.R. (2023). Generative AI at Work. National Bureau of Economic Research.
2. Dell'Acqua, F., McFowland III, E., Mollick, E.R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., Candelon, F., & Lakhani, K.R. (2023). Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality.
3. Noy, S., & Zhang, W. (2023). Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. Science, 381(6654), 187-192.
4. Peng, S., Kalliamvakou, E., Cihon, P., & Demirer, M. (2023). The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint.
5. Rio-Chanona, M., Laurentsyeva, N., & Wachs, J. (2023). Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow. arXiv preprint.